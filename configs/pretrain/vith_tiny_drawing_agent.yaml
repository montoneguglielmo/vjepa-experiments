app: vjepa
nodes: 1
tasks_per_node: 1
data:
  dataset_type: VideoDataset
  datasets:
    - ../datasets/action-drawing-agent/videos_with_action/12800-videos/videos/videos_index.csv
  decode_one_clip: true
  batch_size: 4  # Reduced batch size for small GPU
  num_clips: 1
  num_frames: 16
  tubelet_size: 2
  sampling_rate: 4
  crop_size: 56
  patch_size: 4
  pin_mem: true
  num_workers: 4  # Reduced workers for single GPU
  filter_short_videos: false
  clip_duration: null
logging:
  folder: /home/guglielmo/Projects/experiments_result/action-drawing-agent/action_videos/12800-videos/run1
  write_tag: jepa_tiny
loss:
  loss_exp: 1.0
  reg_coeff: 0.0
mask:
  - mode: time_split
meta:
  load_checkpoint: false
  read_checkpoint: null
  seed: 234
  eval_freq: 100
  use_sdpa: true
  dtype: bfloat16
model:
  model_name: vit_tiny  # Using vit_tiny instead of vit_huge
  pred_depth: 6  # Reduced predictor depth
  pred_embed_dim: 192  # Reduced embedding dimension
  uniform_power: true
  use_mask_tokens: true
  zero_init_mask_tokens: true
optimization:
  ipe: 100  # Reduced iterations per epoch
  ipe_scale: 1.0
  clip_grad: 10.0
  weight_decay: 0.02
  final_weight_decay: 0.2
  epochs: 100  # Reduced number of epochs
  warmup: 30  # Reduced warmup
  start_lr: 0.0001
  lr: 0.0002
  final_lr: 1.0e-06
  ema:
  - 0.998
  - 1.0 