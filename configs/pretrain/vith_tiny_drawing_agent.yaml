app: vjepa
nodes: 1
tasks_per_node: 1
data:
  dataset_type: VideoDataset
  datasets:
    - ../shared/datasets/action-drawing-agent/one-folder-dataset/9600-videos/videos_with_action/videos_index.csv
  decode_one_clip: true
  batch_size: 4  # Reduced batch size for small GPU
  num_clips: 1
  num_frames: 16
  tubelet_size: 2
  sampling_rate: 4
  crop_size: 56
  patch_size: 4
  pin_mem: true
  num_workers: 0  # Reduced workers for single GPU
  filter_short_videos: false
  clip_duration: null
logging:
  folder: ../shared/experiments_result/action-drawing-agent/one-folder-dataset/9600-videos/action_videos/run1
  write_tag: jepa_tiny
loss:
  loss_exp: 1.0
  reg_coeff: 0.0
mask:
  - mode: time_split
meta:
  load_checkpoint: false
  read_checkpoint: null
  seed: 234
  eval_freq: 100
  use_sdpa: true
  dtype: bfloat16
debug:
  enabled: true
model:
  model_name: vit_tiny  # Using vit_tiny instead of vit_huge
  pred_depth: 6  # Reduced predictor depth
  pred_embed_dim: 192  # Reduced embedding dimension
  uniform_power: true
  use_mask_tokens: true
  zero_init_mask_tokens: true
optimization:
  ipe: 100  # Reduced iterations per epoch
  ipe_scale: 1.0
  clip_grad: 10.0
  weight_decay: 0.02
  final_weight_decay: 0.2
  epochs: 2000  # Reduced number of epochs
  warmup: 30  # Reduced warmup
  start_lr: 0.0002
  lr: 0.0006
  final_lr: 1.0e-06
  ema:
  - 0.99999
  - 1.0